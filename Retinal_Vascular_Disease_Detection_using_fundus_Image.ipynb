{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "\n",
        "# Retinal Vascular Disease Detection using fundus image\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "## Introduction\n",
        "Diabetic Retinopathy (DR) is a serious eye condition that can lead to blindness\n",
        "if not detected early. This project leverages deep learning techniques using InceptionV3 to classify fundus images into different DR severity levels. The model is trained on preprocessed fundus images to classify them into five categories:\n",
        "*   No DR (Healthy Retina)\n",
        "*   Mild NPDR (Non-Proliferative Diabetic Retinopathy)\n",
        "*   Moderate NPDR\n",
        "*   Severe NPDR\n",
        "*   PDR (Proliferative Diabetic Retinopathy)\n",
        "\n",
        "This solution provides an automated system that assists ophthalmologists in early detection and diagnosis of Diabetic Retinopathy.\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "## Objective\n",
        "The primary objective of this project is to develop a deep learning model using the InceptionV3 architecture to automatically classify retinal images into different stages of Diabetic Retinopathy with high accuracy.\n",
        "\n",
        "*   Preprocess and augment the dataset for improved model generalization.\n",
        "*   Implement Transfer Learning using InceptionV3.\n",
        "*   Train and evaluate the deep learning model for accurate DR detection.\n",
        "*   Deploy the model using Flask and Gradio for easy accessibility.\n",
        "\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "## Aim of the Project\n",
        "\n",
        "*   To train and fine-tune an InceptionV3-based model on a labeled dataset of\n",
        "fundus images.\n",
        "*   To evaluate the performance of the trained model on unseen test data.\n",
        "*   To deploy the trained model using Flask and Gradio for real-time predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "astRqqDnxRPr"
      },
      "id": "astRqqDnxRPr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Required Libraries\n",
        "This block loads essential libraries for data processing, model building, augmentation, and evaluation."
      ],
      "metadata": {
        "id": "V0RVpUaTywJP"
      },
      "id": "V0RVpUaTywJP"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D,Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.initializers import glorot_uniform,he_uniform\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l1_l2"
      ],
      "metadata": {
        "id": "GDSuLVWwxPVd"
      },
      "id": "GDSuLVWwxPVd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Dataset Paths\n",
        "This section sets the file paths for training, validation, and testing datasets."
      ],
      "metadata": {
        "id": "chmpxcttzG7c"
      },
      "id": "chmpxcttzG7c"
    },
    {
      "cell_type": "code",
      "source": [
        "# File paths\n",
        "train_dir = \"C:/Users/Nasir/Downloads/OUR/OUR/TRAIN\"\n",
        "val_dir = \"C:/Users/Nasir/Downloads/OUR/OUR/VALIDATION\"\n",
        "test_dir = \"C:/Users/Nasir/Downloads/OUR/OUR/TEST\""
      ],
      "metadata": {
        "id": "nXkwQf8SzCUm"
      },
      "id": "nXkwQf8SzCUm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and Preprocessing Data\n",
        "\n",
        "*   Loads images from the dataset directories.\n",
        "*   Resizes them to 299x299 (required for InceptionV3).\n",
        "*   Normalizes pixel values to [0,1] range.\n",
        "*   Assigns labels based on folder names.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f8pn8NjtzHXz"
      },
      "id": "f8pn8NjtzHXz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data (same as before)\n",
        "def load_data(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_dict = {\n",
        "        'nodr': 0,\n",
        "        'mild_npdr': 1,\n",
        "        'moderate_npdr': 2,\n",
        "        'severe_npdr': 3,\n",
        "        'pdr': 4\n",
        "    }\n",
        "\n",
        "    for label_name, label_index in label_dict.items():\n",
        "        label_dir = os.path.join(directory, label_name)\n",
        "        for img_name in os.listdir(label_dir):\n",
        "            img_path = os.path.join(label_dir, img_name)\n",
        "            img = image.load_img(img_path, target_size=(299, 299))  # Resize to InceptionV3's required size\n",
        "            img_array = image.img_to_array(img) / 255.0  # Normalize\n",
        "            images.append(img_array)\n",
        "            labels.append(label_index)\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "qqco0R4_zFRZ"
      },
      "id": "qqco0R4_zFRZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Train, Validation, and Test Datasets\n",
        "This loads the dataset using the load_data function."
      ],
      "metadata": {
        "id": "6cVS7RE7y26J"
      },
      "id": "6cVS7RE7y26J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c99400f5-6af5-4e8a-b8ab-7bafd6dcc9cc",
      "metadata": {
        "id": "c99400f5-6af5-4e8a-b8ab-7bafd6dcc9cc"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "x_train, y_train = load_data(train_dir)\n",
        "x_val, y_val = load_data(val_dir)\n",
        "x_test, y_test = load_data(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31dfd61d-c2bb-4d7c-a7da-68a5714ed83b",
      "metadata": {
        "id": "31dfd61d-c2bb-4d7c-a7da-68a5714ed83b"
      },
      "outputs": [],
      "source": [
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(np.unique(y_train))  # Total number of classes\n",
        "y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "y_val = to_categorical(y_val, num_classes=num_classes)\n",
        "y_test = to_categorical(y_test, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ec508f3-162a-4d13-9cca-1ad4762075f0",
      "metadata": {
        "id": "7ec508f3-162a-4d13-9cca-1ad4762075f0"
      },
      "outputs": [],
      "source": [
        "input_dim = x_train.shape\n",
        "input_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64cdfe33",
      "metadata": {
        "id": "64cdfe33"
      },
      "outputs": [],
      "source": [
        "y_train.shape,x_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa1df621",
      "metadata": {
        "id": "fa1df621"
      },
      "outputs": [],
      "source": [
        "x_test.shape,y_val.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the InceptionV3 Model\n",
        "This defines a deep learning model with:\n",
        "\n",
        "\n",
        "*   InceptionV3 as the base model\n",
        "*   Fully connected layers with batch normalization, dropout, and activation functions.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s_syt37Gzdvp"
      },
      "id": "s_syt37Gzdvp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bb1a1e7-f6e9-4a2b-9ee7-6d5bac22da6b",
      "metadata": {
        "id": "1bb1a1e7-f6e9-4a2b-9ee7-6d5bac22da6b"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "    base_model.trainable = False  # Freeze the base model initially\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(GlobalAveragePooling2D())  # Global average pooling to reduce dimensions\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(1024, activation='relu', kernel_initializer=he_uniform()))\n",
        "    model.add(BatchNormalization())  # Batch normalization\n",
        "\n",
        "    model.add(Dense(512, activation='relu', kernel_initializer=he_uniform()))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))  # Dropout layer with rate 0.2 (alternate)\n",
        "\n",
        "    model.add(Dense(256, activation='relu', kernel_initializer=he_uniform()))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))  # Final output layer for classification\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38fa3b01-8975-4ec1-8fa3-13d125a9f427",
      "metadata": {
        "id": "38fa3b01-8975-4ec1-8fa3-13d125a9f427"
      },
      "outputs": [],
      "source": [
        "model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9541cc9-7b48-4029-ab6c-c9e241b5260e",
      "metadata": {
        "id": "a9541cc9-7b48-4029-ab6c-c9e241b5260e"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation for Training\n",
        "This applies transformations like rotation, shifting, shearing, and flipping for robust training."
      ],
      "metadata": {
        "id": "TFpzWERwzl78"
      },
      "id": "TFpzWERwzl78"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36764189-7d7b-4f61-8478-88b2863a2d9c",
      "metadata": {
        "id": "36764189-7d7b-4f61-8478-88b2863a2d9c"
      },
      "outputs": [],
      "source": [
        "# Data augmentation setup (put this before model.fit)\n",
        "train_datagen = ImageDataGenerator(\n",
        "\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model\n",
        "Fits the model using augmented training data."
      ],
      "metadata": {
        "id": "NXYE5aFDzzV5"
      },
      "id": "NXYE5aFDzzV5"
    },
    {
      "cell_type": "code",
      "source": [
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)callbacks=[early_stopping],\n",
        "\n",
        "# Fit the model with fine-tuning\n",
        "history = model.fit(\n",
        "    train_datagen.flow(x_train, y_train, batch_size=128),  # Corrected flow syntax\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=20,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "sSL3Y0MnzysL"
      },
      "id": "sSL3Y0MnzysL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation\n",
        "Evaluates performance on test data."
      ],
      "metadata": {
        "id": "9446pSaTzrnt"
      },
      "id": "9446pSaTzrnt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0af459e9-3f8a-4290-8975-d26962fe7343",
      "metadata": {
        "id": "0af459e9-3f8a-4290-8975-d26962fe7343"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Plotting\n",
        "Plots training vs validation loss."
      ],
      "metadata": {
        "id": "wUzfTYImz8JP"
      },
      "id": "wUzfTYImz8JP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1e656f6-3a96-4a88-bfc1-ccd4712ea468",
      "metadata": {
        "id": "f1e656f6-3a96-4a88-bfc1-ccd4712ea468"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title(\"Train Vs Val Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlim(0, 50)\n",
        "plt.xticks(range(0, 51, 2))\n",
        "plt.ylim(0, 70)\n",
        "plt.yticks(range(0, 71, 4))\n",
        "plt.legend(['Val_loss','loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flask Implementation for Deployment\n",
        "This Flask app serves the model for real-time predictions."
      ],
      "metadata": {
        "id": "-VaQ0a3g0AFb"
      },
      "id": "-VaQ0a3g0AFb"
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load trained model\n",
        "model = create_model()\n",
        "model.load_weights(\"C:/Users/Nasir/Downloads/OUR/model_weights.h5\")\n",
        "\n",
        "# Class labels\n",
        "class_labels = ['No DR', 'Mild NPDR', 'Moderate NPDR', 'Severe NPDR', 'PDR']\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    file = request.files['image']\n",
        "    img = image.load_img(file, target_size=(299, 299))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    class_idx = np.argmax(predictions)\n",
        "\n",
        "    return jsonify({'prediction': class_labels[class_idx]})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "eHEehV1I0DCl"
      },
      "id": "eHEehV1I0DCl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio Implementation for Deployment"
      ],
      "metadata": {
        "id": "E_uJZaUG0Lbb"
      },
      "id": "E_uJZaUG0Lbb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c5b42e8-d68d-436a-b055-591d54f71792",
      "metadata": {
        "id": "3c5b42e8-d68d-436a-b055-591d54f71792"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "model = create_model()\n",
        "model.load_weights('\"C:/Users/Nasir/Downloads/OUR/51_r1.jpg\".h5')\n",
        "\n",
        "def predict_image(img):\n",
        "    img = img.resize((299, 299))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    predictions = model.predict(img_array)\n",
        "    class_idx = np.argmax(predictions)\n",
        "    class_labels = ['No DR', 'Mild NPDR', 'Moderate NPDR', 'Severe NPDR', 'PDR']\n",
        "    predicted_class = class_labels[class_idx]\n",
        "    return f'Predicted class: {predicted_class}'\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_image,\n",
        "    inputs=gr.inputs.Image(shape=(299, 299)),\n",
        "    outputs=\"text\",\n",
        "    title=\"Diabetic Retinopathy Detection\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "This project successfully implements Diabetic Retinopathy detection using deep learning. The trained InceptionV3 model classifies fundus images into different severity levels. The final model is deployed using Flask and Gradio, allowing users to upload retinal images and get predictions."
      ],
      "metadata": {
        "id": "qofu8Cau0HUk"
      },
      "id": "qofu8Cau0HUk"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}